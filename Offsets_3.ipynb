{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1993a8b8",
   "metadata": {},
   "source": [
    "# Image Offsets: Create offset arrays used by drizzle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04ec8a",
   "metadata": {},
   "source": [
    "The offset tables created by a previous notebook (Offsets_2) are used to generate the X and Y offset arrays used by drizzle.\n",
    "\n",
    "Each offset table will generate 2 arrays, for X and Y respectively, stored as FITS image of short float type.\n",
    "\n",
    "The algorithms were developed in the Timing notebook; here, they are cast as callable functions used in a loop to process all images in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2fabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from astropy.table import Table\n",
    "\n",
    "import rawpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a47c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../astrophotography_data/MilkyWayPrettyBoy/12800/light/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae480c2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59f515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison functions\n",
    "gt_zero = lambda x: x > 0.0\n",
    "lt_zero = lambda x: x < 0.0\n",
    "\n",
    "# Gets the index of the closest star in table. \n",
    "# The differences are in the sense pixel - star centroid.\n",
    "# The comparison functions define from which quadrant the star is drawn from.\n",
    "def closest(diff_x, diff_y, compare_x, compare_y):\n",
    "    # Compute mask that masks out everything that is outside \n",
    "    # the quadrant defined by the comparison functions\n",
    "    mask_x = np.where(compare_x(diff_x), 1, 0)\n",
    "    mask_y = np.where(compare_y(diff_y), 1, 0)\n",
    "    mask = mask_x * mask_y\n",
    "\n",
    "    # Get index of star at minimum distance\n",
    "    distance = np.sqrt((diff_x * diff_x + diff_y * diff_y)) * mask\n",
    "    if np.nonzero(distance)[0].size > 0:\n",
    "        mindist = np.min(distance[np.nonzero(distance)])\n",
    "        index = np.where(distance == mindist )[0][0]\n",
    "        return index, mindist\n",
    "    else:\n",
    "        return -1, 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81dced",
   "metadata": {},
   "source": [
    "## Parallelization functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e08a14",
   "metadata": {},
   "source": [
    "The offset computation for each individual pixel is prohibitive without parallelization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fadb6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker:\n",
    "    '''\n",
    "    A class with callable instances that execute the offset calculation\n",
    "    algorithm over a section of the input image. It provides the callable \n",
    "    for the `Pool.apply_async` function, and also holds all parameters \n",
    "    necessary to perform the calculation.\n",
    "    '''\n",
    "    def __init__(self, x0, y0, size_x, size_y, step_x, step_y, centroid_x, centroid_y, \n",
    "                offset_x, offset_y, offset_array_x, offset_array_y):\n",
    "        '''\n",
    "        Parameters:\n",
    "        \n",
    "        x0, y0 - top left pixel of the image section designated for this instance\n",
    "        size_x, size_ - size of the image section\n",
    "        step_x - step used in the x direction when looping over pixels\n",
    "        step_y - step used in the y direction when looping over pixels\n",
    "        centroid_x - 1-D data from the `xcentroid` column in the offsets table \n",
    "        centroid_y - 1-D data from the `ycentroid` column in the offsets table \n",
    "        offset_x - 1-D data from the `xoffset` column in the offsets table \n",
    "        offset_y - 1-D data from the `yoffset` column in the offsets table \n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "        offset_array_x - output array with the x offsets for every `step_x` pixel\n",
    "        offset_array_y - output array with the y offsets for every `step_y` pixel\n",
    "        '''\n",
    "        self.x0 = x0\n",
    "        self.y0 = y0\n",
    "        self.size_x = size_x\n",
    "        self.size_y = size_y\n",
    "        self.step_x = step_x\n",
    "        self.step_y = step_y\n",
    "\n",
    "        self.centroid_x = centroid_x\n",
    "        self.centroid_y = centroid_y\n",
    "        self.offset_x = offset_x\n",
    "        self.offset_y = offset_y\n",
    "        self.offset_array_x = offset_array_x\n",
    "        self.offset_array_y = offset_array_y\n",
    "\n",
    "    def __call__(self):\n",
    "        max_x = self.x0 + self.size_x\n",
    "        max_y = self.y0 + self.size_y\n",
    "\n",
    "        for i in range(self.x0, max_x, self.step_x):\n",
    "            for j in range(self.y0, max_y, self.step_y):\n",
    "        # for i in range(2000, 2001):\n",
    "        #     for j in range(1000, 1003):\n",
    "\n",
    "                pixel_x = i\n",
    "                pixel_y = j\n",
    "\n",
    "                diff_x = pixel_x - self.centroid_x\n",
    "                diff_y = pixel_y - self.centroid_y\n",
    "\n",
    "                index = np.array(range(4), dtype=int)\n",
    "                dist  = np.array(range(4), dtype=float)\n",
    "\n",
    "                # get index and distance of the closest star, one per quadrant\n",
    "                index[0], dist[0] = closest(diff_x, diff_y, gt_zero, gt_zero)\n",
    "                index[1], dist[1] = closest(diff_x, diff_y, lt_zero, gt_zero)\n",
    "                index[2], dist[2] = closest(diff_x, diff_y, gt_zero, lt_zero)\n",
    "                index[3], dist[3] = closest(diff_x, diff_y, lt_zero, lt_zero)\n",
    "\n",
    "                # need a cleanup here. Negative indices, zeroed distances.\n",
    "\n",
    "                # weighted average of the offset values. The weight is the inverse distance pixel-star.\n",
    "                sumweights = 0.0\n",
    "                for k in range(len(dist)):\n",
    "                    if dist[k] > 0.:\n",
    "                        sumweights += 1./dist[k]\n",
    "                        \n",
    "                weighted_offset_x = 0.0\n",
    "                weighted_offset_y = 0.0\n",
    "\n",
    "                for k in range(len(index)):\n",
    "                    if index[k] > 0:\n",
    "                        weighted_offset_x += self.offset_x[index[k]] * (1./dist[k] / sumweights)\n",
    "                        weighted_offset_y += self.offset_y[index[k]] * (1./dist[k] / sumweights)\n",
    "\n",
    "                self.offset_array_x[j][i] = weighted_offset_x\n",
    "                self.offset_array_y[j][i] = weighted_offset_y\n",
    "                \n",
    "#                 if (i == 1000):\n",
    "#                     print(i, j, self.offset_array_x[j][i], sumweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c10a7",
   "metadata": {},
   "source": [
    "## Read last table in sequence, and prototype image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b6749",
   "metadata": {},
   "source": [
    "Starting with the last table ensures that we get always the same stars along the entire sequence. Offset tables at the beginning of the sequence may include stars that are dropped later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9fedbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last table in sequence\n",
    "table_list = glob.glob(datadir + '/*.offsets_table.fits')\n",
    "table_list.sort()\n",
    "last = table_list[-1]\n",
    "offsets_table = Table.read(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c93ba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4256 2848\n"
     ]
    }
   ],
   "source": [
    "# prototype image (used to define array size)\n",
    "image_name = last.split('/')[-1]\n",
    "image_name = image_name.replace('.offsets_table.fits', '.ARW')\n",
    "image_name = os.path.join(datadir, image_name)\n",
    "raw = rawpy.imread(image_name)\n",
    "imarray = raw.raw_image_visible.astype(float)\n",
    "\n",
    "# this makes indices consistent with daofind-defined centroids\n",
    "nx = imarray.shape[1]\n",
    "ny = imarray.shape[0]\n",
    "\n",
    "print(nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e63e1be",
   "metadata": {},
   "source": [
    "## Create output arrays and get data from offsets table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1493ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one pair for each of two threads\n",
    "offset_array_x_1 = np.asarray(imarray) * 0.0\n",
    "offset_array_y_1 = np.asarray(imarray) * 0.0\n",
    "\n",
    "offset_array_x_2 = np.asarray(imarray) * 0.0\n",
    "offset_array_y_2 = np.asarray(imarray) * 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457c25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_x = offsets_table['xcentroid'].data\n",
    "centroid_y = offsets_table['ycentroid'].data\n",
    "offset_x = offsets_table['xoffset'].data\n",
    "offset_y = offsets_table['yoffset'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6af24a",
   "metadata": {},
   "source": [
    "## Populate output arays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d52e348",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# w = Worker(0, 0, nx, ny, 10, 10, centroid_x, centroid_y, offset_x, offset_y, offset_array_x, offset_array_y)\n",
    "\n",
    "results = []\n",
    "pool = Pool(2)\n",
    "\n",
    "# each thread outputs in a separate array\n",
    "w1 = Worker(0, 0, int(nx/2), ny, 5, 5, centroid_x, centroid_y, offset_x, offset_y, \n",
    "            offset_array_x_1, offset_array_y_1)\n",
    "w2 = Worker(int(nx/2)+1, 0, int(nx/2), ny, 5, 5, centroid_x, centroid_y, offset_x, offset_y, \n",
    "            offset_array_x_2, offset_array_y_2)\n",
    "\n",
    "#TODO still missing the callback code!\n",
    "\n",
    "r = pool.apply_async(w1)\n",
    "results.append(r)\n",
    "r = pool.apply_async(w2)\n",
    "results.append(r)\n",
    "\n",
    "for r in results:\n",
    "    r.wait()\n",
    "\n",
    "pool.close()\n",
    "\n",
    "# alternate, non-threaded version to test the worker code\n",
    "# w1()\n",
    "# w2()\n",
    "\n",
    "\n",
    "# here we have to merge together the two output arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fed954c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_array_x_1[1500:1510,1500:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b260b2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_array_x_1[1500:1510,3500:3510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "213eebef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_array_x_2[1500:1510,1500:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7135a3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_array_x_2[1500:1510,3500:3510]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
