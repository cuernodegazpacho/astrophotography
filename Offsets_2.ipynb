{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Offsets: Process sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook transforms the procedures developed in `Offsets_1.ipynb` into callable functions. \n",
    "\n",
    "These functions are used in a loop to process an entire sequence of images. Results are later examined in plots. \n",
    "\n",
    "The end product is a series of FITS tables, one per input image, that contain the star offsets in relation to the reference image. These tables should be used in a subsequent notebook to generate the actual arrays with pixel offsets that are used by drizzle to figure out the pixel mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "import os, glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from astropy.table import Table, vstack\n",
    "from astropy.stats import SigmaClip\n",
    "\n",
    "import photutils\n",
    "from photutils import Background2D, ModeEstimatorBackground, DAOStarFinder, CircularAperture\n",
    "\n",
    "import rawpy\n",
    "import exifread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define values to be used in the processing functions, and throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '../astrophotography_data/MilkyWayPrettyBoy/12800/light/'\n",
    "file_list = glob.glob(dirpath + '/*.ARW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for background subtraction and star finding\n",
    "bkg_sigma = 3.0\n",
    "bkg_cell_footprint = (50, 50)\n",
    "bkg_filter = (5, 5)\n",
    "dao_fwhm = 4.3\n",
    "dao_threshold = 5.0\n",
    "proximity = 2.5\n",
    "\n",
    "# operators\n",
    "sigma_clip = SigmaClip(sigma=bkg_sigma)\n",
    "bkg_estimator = ModeEstimatorBackground()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st test image - this will be the reference image which subsequent images\n",
    "# will have their offsets computed against. We need to read it here to get \n",
    "# the camera color array specification as well.\n",
    "fname = file_list[0]\n",
    "raw = rawpy.imread(fname)\n",
    "ref_imarray = raw.raw_image_visible.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks that isolate the RGB pixels - these are camera-dependent and work with all images\n",
    "colors_array = raw.raw_colors_visible\n",
    "\n",
    "red_mask = np.where(colors_array == 0, 1, 0)\n",
    "\n",
    "green_mask_1 = np.where(colors_array == 1, 1, 0)\n",
    "green_mask_2 = np.where(colors_array == 3, 1, 0)\n",
    "green_mask = green_mask_1 | green_mask_2\n",
    "\n",
    "blue_mask = np.where(colors_array == 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization factors for the RGB arrays\n",
    "# red_norm = 1.321875  # smooth background  \n",
    "# green_norm = 1.\n",
    "# blue_norm = 1.27695312\n",
    "\n",
    "red_norm = 1.9  # spectrum\n",
    "green_norm = 1.\n",
    "blue_norm = 1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using normalizations derived from passband spectral response is *much* better than using normalizations derived from minimization of sky background variance (contrary to the initial finding in notebook Offsets_1). The likely cause is that the spectral-based normalization creates more well-behaved star images. The high variance in sky background doesn't seem to get in the way of detecting stars.\n",
    "\n",
    "The best run with smooth background generated 240 detections with a complete data set. The same run but with spectral-based color band normalizations resulted in 550 detections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes position offsets between two tables. \n",
    "def get_offsets(sources, sources_prev):\n",
    "\n",
    "    sources.add_column(np.nan, name='xoffset')\n",
    "    sources.add_column(np.nan, name='yoffset')\n",
    "    sources.add_column(0.0, name='xoffset_prev')\n",
    "    sources.add_column(0.0, name='yoffset_prev')\n",
    "    sources.add_column(0, name='ref_row')\n",
    "    sources.add_column(0, name='prev_row')\n",
    "\n",
    "    # loop over rows in previous table\n",
    "    for row_index_prev in range(len(sources_prev)):\n",
    "        # index in reference table\n",
    "        ref_row = sources_prev[row_index_prev]['ref_row']\n",
    "\n",
    "        # if previous table does not contain a pointer to \n",
    "        # the reference table, ignore.\n",
    "        if ref_row == 0:\n",
    "            continue\n",
    "\n",
    "        # get position in previous table\n",
    "        x_prev = sources_prev[row_index_prev]['xcentroid']\n",
    "        y_prev = sources_prev[row_index_prev]['ycentroid']\n",
    "\n",
    "        # loop over rows in current table\n",
    "        for row_index in range(len(sources)):\n",
    "            x = sources[row_index]['xcentroid']\n",
    "            y = sources[row_index]['ycentroid']\n",
    "\n",
    "            # offsets in relation to previous table - these are the ones to check for proximity\n",
    "            x_off_previous = x - x_prev\n",
    "            y_off_previous = y - y_prev\n",
    "\n",
    "            # check for proximity, and store relevant info if found\n",
    "            if abs(x_off_previous) <= proximity and abs(y_off_previous) <= proximity:\n",
    "\n",
    "                # offsets in relation to reference table\n",
    "                sources[row_index]['xoffset'] = x - sources_ref[ref_row]['xcentroid']\n",
    "                sources[row_index]['yoffset'] = y - sources_ref[ref_row]['ycentroid']\n",
    "\n",
    "                # offsets in relation to previous table\n",
    "                sources[row_index]['xoffset_prev'] = x_off_previous\n",
    "                sources[row_index]['yoffset_prev'] = y_off_previous\n",
    "\n",
    "                # store pointers to rows in reference and previous tables\n",
    "                sources[row_index]['ref_row'] = ref_row\n",
    "                sources[row_index]['prev_row'] = row_index_prev\n",
    "                \n",
    "                #TODO \n",
    "                # instead of breaking, do an estimate of where the centroid would be,\n",
    "                # given the current position, and the offsets from the previous table.\n",
    "                # In other words, repeat the offset from the previous table. See if this\n",
    "                # will cause the finding algorithm to pick up in the next image.\n",
    "\n",
    "                break # if there is another star that matches the criterion, just ignore it\n",
    "                \n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a table with star positions, given a path to an image file\n",
    "def find_stars(path, sources_prev=None):\n",
    "\n",
    "    with rawpy.imread(path) as raw:\n",
    "        imarray = raw.raw_image_visible.astype(float)\n",
    "\n",
    "        # normalize\n",
    "        raw_norm_1 = imarray * (red_mask * red_norm)\n",
    "        raw_norm_2 = raw_norm_1 + imarray * (green_mask * 1.0)\n",
    "        raw_norm = raw_norm_2 + imarray * (blue_mask * blue_norm)\n",
    "\n",
    "        # handle saturated pixels\n",
    "        raw_norm = np.where(imarray > 16380, imarray, raw_norm)\n",
    "\n",
    "        # compute and subtract background\n",
    "        bkg = Background2D(raw_norm, bkg_cell_footprint, filter_size=bkg_filter, sigma_clip=sigma_clip, bkg_estimator=bkg_estimator)\n",
    "        subtracted = raw_norm - bkg.background\n",
    "\n",
    "        # find stars\n",
    "        if sources_prev is None:\n",
    "            daofind = DAOStarFinder(fwhm=dao_fwhm, threshold=dao_threshold * bkg.background_rms_median) \n",
    "        else:\n",
    "            # offsets are added in reverse, to generate an estimate further away from the current position.\n",
    "            x_estimate = sources_prev['xcentroid'] - sources_prev['xoffset_prev'] \n",
    "            y_estimate = sources_prev['ycentroid'] - sources_prev['yoffset_prev'] \n",
    "            positions = [(x,y) for x,y in zip(x_estimate, y_estimate)]\n",
    "            daofind = DAOStarFinder(xycoords=np.array(positions), fwhm=dao_fwhm, \n",
    "                                    threshold=dao_threshold * bkg.background_rms_median) \n",
    "        sources = daofind(subtracted)\n",
    "\n",
    "        return sources, subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the NaN-free entries\n",
    "def clean_nans(sources):\n",
    "    has_nan = np.zeros(len(sources), dtype=bool)\n",
    "    xoff = np.array(sources['xoffset'])\n",
    "    has_nan |= np.isnan(xoff)\n",
    "    return sources[~has_nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find stars in reference image\n",
    "files = sort(file_list)\n",
    "sources_ref, subtracted_ref = find_stars(files[0])\n",
    "\n",
    "# positions storage\n",
    "positions_tables = {}\n",
    "positions_tables[files[0]] = sources_ref\n",
    "\n",
    "# array for stacking subtracted images\n",
    "image_stack = np.zeros_like(subtracted_ref)\n",
    "\n",
    "# add default offset columns to reference table\n",
    "sources_ref.add_column(0., name='xoffset')\n",
    "sources_ref.add_column(0., name='yoffset')\n",
    "sources_ref.add_column(0., name='xoffset_prev')\n",
    "sources_ref.add_column(0., name='yoffset_prev')\n",
    "\n",
    "# in ref table, rows point to themselves\n",
    "sources_ref.add_column(sources_ref['id']-1, name='ref_row')\n",
    "sources_ref.add_column(sources_ref['id']-1, name='prev_row')\n",
    "\n",
    "# force reference image to be the \"previous\" image\n",
    "sources_prev = sources_ref\n",
    "\n",
    "sources_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop over list of remaining images\n",
    "for file_path in files[1:]:\n",
    "    \n",
    "    # find stars\n",
    "    sources, subtracted = find_stars(file_path, sources_prev=None)\n",
    "    \n",
    "    # compute offsets\n",
    "    sources_current = get_offsets(sources, sources_prev)\n",
    "    \n",
    "    sources_current_no_nan = clean_nans(sources_current)\n",
    "    \n",
    "    positions_tables[file_path] = sources_current_no_nan\n",
    "    \n",
    "    # save table to file\n",
    "    \n",
    "    # for next iteration, current table becomes previous\n",
    "    sources_prev = sources_current_no_nan\n",
    "    \n",
    "    # update image stack\n",
    "    image_stack += subtracted\n",
    "    \n",
    "    print(file_path, len(sources_current_no_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_current_no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# positions = [(x,y) for x,y in zip(sources_current_no_nan['xcentroid'], sources_current_no_nan['ycentroid'])]\n",
    "# positions_ref = [(x,y) for x,y in zip(sources_ref['xcentroid'], sources_ref['ycentroid'])]\n",
    "\n",
    "# apertures = CircularAperture(positions, r=5.)\n",
    "# apertures_ref = CircularAperture(positions_ref, r=5.)\n",
    "\n",
    "# plt.figure(figsize=[9, 6])\n",
    "# plt.imshow(image_stack, vmin=-10, vmax=10000, cmap='binary')\n",
    "# plt.colorbar()\n",
    "# _ = apertures.plot(color='red')\n",
    "# _ = apertures_ref.plot(color='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[9, 6])\n",
    "plt.imshow(image_stack, vmin=-10, vmax=30000, cmap='binary')\n",
    "plt.colorbar()\n",
    "\n",
    "for file_path in list(positions_tables.keys()):\n",
    "    positions_t = positions_tables[file_path]\n",
    "    positions = [(x,y) for x,y in zip(positions_t['xcentroid'], positions_t['ycentroid'])]\n",
    "    apertures = CircularAperture(positions, r=1.)\n",
    "    _ = apertures.plot(color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only complete stars in sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stars with a complete sequence of measured centroids are the ones that make to the last image/table in the sequence. Thus, starting from the end image and going backwards, we ensure we pick only the complete sequence stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start from last table in sequence \n",
    "file_path_last = list(positions_tables.keys())[-1]\n",
    "positions_last = positions_tables[file_path_last]\n",
    "refrow_last = positions_last['ref_row']\n",
    "\n",
    "file_path_first = list(positions_tables.keys())[0]  # ref table\n",
    "positions_first = positions_tables[file_path_first]\n",
    "\n",
    "plt.figure(figsize=[9, 6])\n",
    "plt.imshow(image_stack, vmin=-10, vmax=30000, cmap='binary')\n",
    "plt.colorbar()\n",
    "\n",
    "for i, row in enumerate(refrow_last):\n",
    "    ref_row = positions_first[row]\n",
    "    \n",
    "    x0 = ref_row['xcentroid']\n",
    "    y0 = ref_row['ycentroid']\n",
    "    x1 = positions_last['xcentroid'][i]\n",
    "    y1 = positions_last['ycentroid'][i]\n",
    "    \n",
    "    plot([x0,x1], [y0,y1], 'r', linewidth=1, markersize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(positions_tables.keys())\n",
    "\n",
    "for key in keys:\n",
    "    dirname = os.path.dirname(key)\n",
    "    fname = os.path.basename(key)\n",
    "    \n",
    "    # get image time and add to table header\n",
    "    f = open( key, 'rb')\n",
    "    tags = exifread.process_file(f)\n",
    "    date_time = tags['EXIF DateTimeOriginal']\n",
    "    \n",
    "    imagename = fname.split('.')[0]\n",
    "    tablename = os.path.join(dirname, imagename + '.offsets_table.fits')\n",
    "    \n",
    "    table = positions_tables[key]\n",
    "\n",
    "    table.write(tablename, format='fits', overwrite=True)\n",
    "\n",
    "    print(date_time, tablename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
